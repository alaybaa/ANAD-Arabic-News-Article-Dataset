أوروبا تريد حظر الذكاء الاصطناعي للمراقبة الجماعية 

 يدرس الاتحاد الأوروبي حظر استخدام الذكاء الاصطناعي لعدد من الأغراض، بما في ذلك المراقبة الجماعية ودرجات الائتمان الاجتماعي.ويأتي ذلك وفقًا لاقتراح تم تسريبه يتم تداوله عبر الإنترنت، تم نشره لأول مرة بواسطة Politico، قبل الإعلان الرسمي المتوقع الأسبوع المقبل.وإذا تم اعتماد مسودة الاقتراح، فقد يفرض الاتحاد الأوروبي موقفًا قويًا بشأن تطبيقات معينة للذكاء الاصطناعي، مما يميزه عن الولايات المتحدة والصين. وتتم مراقبة بعض حالات الاستخدام بطريقة مشابهة للوائح الاتحاد الأوروبي للخصوصية الرقمية بموجب تشريعات اللائحة العامة لحماية البيانات.وقد يُطلب من الدول الأعضاء إنشاء لوحات تقييم لاختبار أنظمة الذكاء الاصطناعي العالية المخاطر والتحقق من صحتها. ويمكن تغريم الشركات التي تطور أو تبيع برامج الذكاء الاصطناعي المحظورة في الاتحاد الأوروبي، بما في ذلك تلك الموجودة في أماكن أخرى من العالم، بنسبة تصل إلى 4 في المئة من إيراداتها العالمية. وتشمل مسودة اللوائح:حظر أنظمة الذكاء للمراقبة العشوائية، بما في ذلك الأنظمة التي تتعقب الأفراد مباشرةً في البيئات المادية أو تجمع البيانات من مصادر أخرى.حظر أنظمة الذكاء التي تنشئ درجات ائتمان اجتماعي، مما يعني الحكم على جدارة شخص ما بالثقة بناءً على السلوك الاجتماعي أو سمات الشخصية المتوقعة.تصريح خاص لاستخدام أنظمة الذكاء لتحديد الهوية عن بُعد مثل التعرف على الوجه في الأماكن العامة.الإخطارات المطلوبة عندما يتفاعل الأشخاص مع أنظمة الذكاء ما لم يكن ذلك واضحًا من الظروف وسياق الاستخدام.إشراف جديد على أنظمة الذكاء العالية الخطورة، بما في ذلك تلك التي تشكل تهديدًا مباشرًا للسلامة، مثل: السيارات الذاتية القيادة، وتلك التي لديها فرصة كبيرة للتأثير في معيشة شخص ما، مثل تلك المستخدمة في التوظيف، وقرارات القضاء، و سجل الائتمان.تقييم أنظمة الذكاء العالية الخطورة قبل وضعها في الخدمة، بما في ذلك التأكد من أن هذه الأنظمة قابلة للتفسير للمشرفين البشريين وأنهم مدربون على مجموعات بيانات عالية الجودة تم اختبارها من أجل التحيز.إنشاء مجلس الذكاء الاصطناعي الأوروبي، الذي يتألف من ممثلين من كل دولة، لمساعدة اللجنة على تحديد أنظمة الذكاء التي تعتبر عالية المخاطر والتوصية بتغييرات في المحظورات.