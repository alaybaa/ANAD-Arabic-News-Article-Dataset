تقرير: محررو فيسبوك يعتمدون على معلومات غير دقيقة 

 دافعت فيسبوك من جديد عن سياساتها ومحرريها ومشرفي المحتوى ضمنها، رافضة التقارير الإعلامية التي تدعي أن الآلاف من المشرفين على المحتوى ضمنها يعتمدون على سلسلة من شرائح PowerPoint وجداول بيانات Excel التي تحتوي على معلومات غير دقيقة وغير منظمة وقديمة لتحديد المحتوى المسموح به على الشبكة الاجتماعية، وهو ما أشار إليه تقرير صادر عن صحيفة نيويورك تايمز الأمريكية.وقالت الصحيفة إن الوثائق تصل إلى أكثر من 1400 صفحة وتستخدم لتوجيه أكثر من 7500 مشرف في فيسبوك فيما يتعلق بموافقتهم أو رفضهم للمحتوى، وأوضحت أن إحدى هذه الشرائح تصف بشكل غير دقيق مجرم الحرب البوسني راتكو ملاديتش Ratko Mladic بأنه لا يزال هاربًا، بالرغم من أنه قد ألقي القبض عليه في عام 2011، في حين أن هناك شريحة أخرى تصف بشكل خاطئ القانون الهندي.وأوضحت المنصة أن النقاش حول اعتدال المحتوى يجب أن يستند إلى حقائق، حيث قالت: “إن صحيفة نيويورك تايمز محقة في أننا نحدث سياساتنا بانتظام لمراعاة المعايير الثقافية واللغوية المتغيرة باستمرار في جميع أنحاء العالم. لكن هذه العملية أبعد ما تكون عن مخصصة لأغراض معينة”. وأضافت فيسبوك أنها تجري تغييرات على السياسات القائمة اعتمادًا على الاتجاهات الجديدة التي يراها المراجعون والتعليقات من داخل الشركة وخارجها، بالإضافة إلى التغييرات غير المتوقعة وفقًا لما يحصل على أرض الواقع، وأن ما تشير إليه الصحيفة على أنه اجتماع صباحي بين المهندسين والمحامين لمحاولة معالجة القضايا بأكثر من 100 لغة مختلفة هو في الواقع منتدى عالمي يعقد كل أسبوعين لمناقشة التغييرات المحتملة على سياساتها.وقالت شركة التواصل الإجتماعي: “ادعت صحيفة نيويورك تايمز بشكل خاطئ أننا عندما ناقشنا جهودنا للحد من خطاب الكراهية في ميانمار فإننا سمحنا، من خلال شرائح PowerPoint الخاطئة، لمجموعة متطرفة بارزة متهمة بالتحريض على الإبادة الجماعية بالبقاء على المنصة لعدة أشهر، لكننا في الوقع، قمنا بتحديد مجموعة Ma Ba Tha كمنظمة للكراهية في شهر أبريل/نيسان 2018، أي قبل ستة أشهر من تواصل الصحيفة معنا لأول مرة بخصوص هذه القصة”.ووفقًا لفيسبوك، فقد بدأت المنصة على الفور بإزالة المحتوى الذي يمثل أو يثني أو يدعم منظمة Ma Ba Tha في شهر أبريل/نيسان، سواء من خلال عمليات المسح الاستباقية لهذا المحتوى أو عند تلقي التقارير من المستخدمين، ويتكون الفريق المسؤول عن الأمان على فيسبوك من حوالي 30 ألف شخص، منهم حوالي 15 ألف شخص من المشرفين والمراجعين للمحتوى حول العالم. كما ادعى التقرير أن المشرفين على المحتوى يعتمدون على مواد تستند إلى تفسيرات غير صحيحة لبعض القوانين الهندية، حيث تخبر الوثائق المشرفين أن أي مشاركة تنتقص أو تنتقد الأديان تشكل انتهاكًا للقانون الهندي، ويجب أن يتم الإبلاغ عنها وتحديدها للإزالة، فيما توضح وثائق أخرى أنه ينبغي على المشرفين البحث عن عبارة “كشمير الحرة”، بالرغم من قانونية هذا الشعار، كما يتم تحذيرهم من أن تجاهل المشاركات التي تستخدم هذه العبارة يمكن أن يعرض فيسبوك للحظر في الهند.وأوضحت فيسبوك أن المشرفين يعملون وفقًا لنظام الحصص، وأن تعويض المراجعين لا يعتمد على مقدار المحتوى الذي يراجعونه، ولا يتوقع من المراجعين الاعتماد على ترجمة جوجل، إذ يتم تزويدهم بالتدريبات والموارد الداعمة، في حين قال التقرير إن المشرفين يحصلون على دخل متدني، ويعملون ضمن ظروف ضاغطة، بحيث ينبغي عليهم مراجعة كل منشور في أقل من عشر ثوان والحكم على ألف منشور في اليوم، مع استخدام ترجمة جوجل.For 2018, my personal challenge has been to focus on addressing some of the most important issues facing our community…Posted by Mark Zuckerberg on Friday, December 28, 2018