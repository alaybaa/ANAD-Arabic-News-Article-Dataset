باحثو جوجل يطورون نظام ذكاء اصطناعي لتحسين تقنية التعرف على الأشياء في الهواتف الذكية 

 تمكن باحثو شركة جوجل في مجال الذكاء الاصطناعي من تطوير نظام آلي يُسمى MnasNet  والذي يعتمد على الذكاء الاصطناعي للتغلب على بطء الاستجابة وعدم الدقة التي تعاني منها تطبيقات التعرف على الأشياء وتصنيف الصور والتعرف على الوجوه في الهواتف الذكية.ومن المعلوم أن الكثير من الشركات المصنعة للهواتف قد بدأت في الإعتماد على هذه التطبيقات، ومنها خدمة Google Lens، التي طرحت منها جوجل إصدارًا جديدًا لتكون متاحة عبر تطبيق الكاميرا في الهواتف الذكية بدلاً من تطبيق صور جوجل، وأعلنت خلال فعاليات مؤتمرها السنوي للمطورين Google I/O 2018 أنه سيتم دمج Google Lens في 10 كاميرات مختلفة للأجهزة العاملة بنظام أندرويد، وتطبيق سناب شات Snapchat أيضًا الذي يمكن من خلاله التعرف على الأشياء.تعتمد هذه التطبيقات في عملها على نماذج التعلم الآلي الأكثر استخدامًا وهي الشبكات العصبية التلافيفية CNNs والتي تعاني من البطء أو عدم الدقة، حيث يعد تصميم شبكات CNN للأجهزة المحمولة أمرًا صعبًا نظرًا لأن نماذج الهواتف يجب أن تكون صغيرة وسريعة، وعلى الرغم من الجهود الكبيرة التي تم بذلها لتصميم وتحسين النماذج المتنقلة، مثل MobileNet و MobileNetV، إلا أن إنشاء نماذج فعالة لا يزال يمثل تحديًا. في الورقة البحثية التي نشرها باحثو جوجل وتحمل اسم “MnasNet: منصة التعرف على بحث الشبكات العصبية للهواتف” يصف الفريق نظامًا آليًا يُسمي MnasNet، للبحث عن الهندسة العصبية لتصميم نماذج متحركة باستخدام أسلوب من أساليب التعلم الآلي يُعرف باسم التعلم التعزيزي (Reinforcement learning (RL، وذلك للتعامل مع قيود التنقل بسرعة بالهاتف للتعرف على الأشياء، حيث قام الباحثون بدمج معلومات السرعة في وظيفة التعرف الرئيسية لخوارزمية البحث، بحيث يمكن أن يحدد البحث نموذجًا يحقق مفاضلة جيدة بين الدقة والسرعة.وقد تمكن MnasNet من العثور والتعرف على الأشياء بمعدل أسرع 1.5 مرة من MobileNetV2 المتطور، وأسرع بمعدل 2.4 من NASNet، بينما وصل إلى نفس مستوي ImageNet  وهي قاعدة بيانات للصور تم تطويرها بواسطة جامعتي ستانفورد وبرنستون والمصنفة على أنها رقم 1 في الدقة.استخدم الباحثون هواتف جوجل بيكسل Pixel في هذه الدراسة البحثية، لقياس أداءها في العالم الحقيقي، وبناء عليه كتب الباحثون في منشور بمدونة جوجل: “بهذه الطريقة يمكننا قياس ما يمكن تحقيقه في الممارسة الواقعية مباشرة، نظراً لأن كل نوع من الأجهزة المحمولة له مواصفاته الخاصة في البرمجيات وأجزاء الهاردوير وقد يتطلب مواصفات مختلفة لأفضل المقايضات بين الدقة والسرعة”. يتكون النظام من ثلاثة أجزاء:الجزء الأول: شبكة عصبيّة RNN تعتمد على متحكم controller، لتتعلم وتصنف البناء الخاص بالنماذج .الجزء الثاني:  مدرب trainer يقوم ببناء النماذج وتدريبها الجزء الثالث: محرك الاستدلال لقياس سرعة النموذج على الهواتف المحمولة الحقيقية باستخدام TensorFlow Lite.وكتب فريق البحث قائلاً: “يسعدنا أن نرى أن منهجنا الآلي يمكن أن يحقق أداءً متطورًا فيما يخص التنقل بسرعة بالهاتف للتعرف على الأشياء، وفي المستقبل نخطط لدمج المزيد من العمليات والتحسينات في مساحة البحث الخاصة بنا، وتطبيقها على مهام رؤية أكثر جاذبية مثل التجزئة الدلالية semantic segmentation”.   