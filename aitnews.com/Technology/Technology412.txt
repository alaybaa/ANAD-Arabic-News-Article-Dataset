المفوضية الأوروبية تضع مبادئ توجيهية أخلاقية لتقنية الذكاء الاصطناعي 

 قالت المفوضية الأوروبية اليوم الاثنين إن الشركات التي تعمل في مجال الذكاء الاصطناعي تحتاج إلى تثبيت آليات المساءلة لمنع إساءة استخدام التقنية، وذلك بموجب مبادئ توجيهية أخلاقية جديدة لتقنية مفتوحة أمام “الأنظمة الاستبدادية”.وقالت المفوضية إن مشاريع الذكاء الاصطناعي يجب أن تكون شفافة، وأن تكون خاضعة للإشراف البشري، ولِلُوغاريتمات آمنة وموثوقة، وأن تخضع لقواعد حماية الخصوصية والبيانات، إلى جانب توصيات أخرى.وتحاول مبادرة الاتحاد الأوروبي الجديدة التدخل في نقاش عالمي بشأن متى – أو هل – يتعين على الشركات أن تجعل المخاوف الأخلاقية مقدمة على المصالح التجارية، ومدى قدرة المنظمين على تحمل نفقات المشاريع الجديدة، دون المخاطرة بقتل الابتكار. وقال أندريس أنسيب، رئيس اللجنة الرقمية لدى المفوضية الأوروبية في بيان: “البعد الأخلاقي للذكاء الاصطناعي ليس ميزة فاخرة، أو وظيفة إضافية. فهو يعتمد على ثقة أنه يمكن لمجتمعنا الاستفادة بالكامل من التقنيات”.ويمكن أن يساعد الذكاء الاصطناعي على اكتشاف تهديدات الاحتيال، والأمن السيبراني، وتحسين الرعاية الصحية، وإدارة المخاطر المالية، ومعالجة تغير المناخ. ولكن يمكن استخدامه أيضًا لدعم الممارسات التجارية “لعديمي الضمير والحكومات الاستبدادية”.وقد استعان المسؤول التنفيذي في الاتحاد الأوروبي العام الماضي بمساعدة 52 خبيرًا من الأوساط الأكاديمية والهيئات الصناعية والشركات، بما في ذلك جوجل و “إس أي بي” SAP، و”سانتاندر” Santander، و”باير” Bayer لمساعدتها في صياغة المبادئ.  ويمكن للشركات والمؤسسات الاشتراك في مرحلة تجريبية للإرشادات الجديدة في شهر حزيران/ يونيو القادم، وبعد ذلك سيقوم الخبراء بمراجعة النتائج، ثم تبت اللجنة في الخطوات التالية. وقال مارتن جيتير رئيس شركة “آي بي إم أوروبا” IBM Europe: “إن الإرشادات تضع معيارًا عالميًا للجهود المبذولة لتعزيز الذكاء الاصطناعي الذي يتسم بالأخلاق والمسؤولية”.