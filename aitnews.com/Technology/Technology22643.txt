مستقبل الإنسانية بلا أخلاق 

 بقلم :  د. عمار بكارهناك عدة أفلام سينمائية تتحدث عن سيطرة الآلة على الإنسان، وأشهرها طبعا فيلم “ماتريكس”، والذي جسد احتقار الآلة الذكية للإنسان واستخدامه لأغراضها. في 1999 ـ لما ظهر الفيلم ـ كان هذا مجرد خيال علمي بحت، ولكننا اليوم مع نضوج مفاهيم الذكاء الاصطناعي، والتي تقوم على “التعلم العميق” (Deep Learning) لدى الأنظمة الذكية، وقدرتها على التطوير الذاتي، فإن هذا الخيال العلمي بدأ يتحول تدريجيا إلى واقع محتمل.ستستغرب عندما تقرأ مقولات لشخصيات مثل ستيفين هوكينغ، وبيل غيتس، وإيلون ماسك والتي تحذر من ذلك، ومن ذلك ما قاله ستيفين هوكينغ، أحد أعظم فيزيائي القرن، بأن “التطوير الكامل للذكاء الاصطناعي قد يعني نهاية الجنس البشري”. ولكن بعيدا عن هذه النظرة المستقبلية البعيدة نسبيا، تواجه شركات التقنية اليوم تحديا أساسيا مرتبطا بـ”أخلاقيات الذكاء الاصطناعي”، وذلك تحت ضغط العديد من المؤسسات الأكاديمية ومراكز الأبحاث المتخصصة في قضايا الأخلاق، وتحت ضغط كبار المبرمجين الذين بدأوا يدركون أن قراراتهم اليومية حول كيفية برمجة أنظمة الذكاء الاصطناعي قد يكون لها أثر كبير على الإنسانية في المستقبل.الآلة تطور نفسها بنفسها من خلال ارتباطها بكمية هائلة من “البيانات الضخمة” التي تم جمعها من مصادر مختلفةهذا ما دفع شركة مثل غوغل لتؤسس مجلسا أعلى خاصا بالأخلاقيات، ودفع فيسبوك لتؤسس مركز أبحاث متخصص في هذا الشأن في ألمانيا، بينما ترعى أمازون أبحاثا حول التعامل العادل في أنظمة الذكاء الاصطناعي، وجعل ميكروسوفت تعلن عن وثيقة المبادئ والأخلاق في تطويرها للذكاء الاصطناعي.حتى أشرح الموضوع قليلا، تخيل معي التالي: خلال سنوات قليلة قادمة ستتمكن الآلة أن تحل محل الجندي في الحرب، والطبيب في المستشفى، والمعالج النفسي، وشرطي السير، وممرضة كبار السن. كل هؤلاء اليوم يتعاملون بناء على أطر أخلاقية معينة تحكم سلوكهم، ويتم محاسبتهم على أساسها. من سيضمن لنا أن الآلة ستحمل نفس المبادئ والأخلاق؟ إذا انطلقت طائرة بدون طيار مسيرة على أسس الذكاء الاصطناعي (وليس التحكم عن بعد كما هو الحال الآن) وقتلت مجموعة من الأطفال لأن الكود البرمجي فيها جعلها تفعل ذلك، من سيتحمل مسؤولية ذلك؟ إذا قام المعالج النفسي الآلي بإرشاد المريض لمجموعة من التصرفات اللاأخلاقية لمعالجة مشكلته، من سنلوم بالضبط؟ الجواب السهل هو أن نلوم الشركة التقنية، والتي بدورها ستلوم فريق البرمجة، ولكن الحقيقة أن التعلم الذاتي يجعل ذلك صعبا جدا، لأن الآلة تطور نفسها بنفسها من خلال ارتباطها بكمية هائلة من “البيانات الضخمة” التي تم جمعها من مصادر مختلفة وعبر فترات زمنية طويلة، وهنا يصبح دور المبرمج محدودا في تحمل المسؤولية.هذا المثال وغيره من أمثلة كثيرة مطروحة تجعل هذه القضية تحت الضوء لدى معظم مراكز الأبحاث المتخصصة في مجال الأخلاقيات عموما، ولكن ما يتم عمله حتى الآن محدود جدا ولا يتعدى بعض الأمور الشكلية فقط. حتى الجهود التي تبذلها الشركات التقنية الضخمة هي ـ كما يقول بعض النقاد ـ مجرد معالجة ظاهرية وإعلامية للموضوع، وتنتهي في الغالب بكتابة تحذير بخط صغير جدا يوافق عليه كل مستخدم بشكل تلقائي دون أن تكون هناك جهود حقيقية وعميقة لمعالجة هذه المشكلات.وماذا عن المؤسسات التشريعية في الحكومات مثل الكونغرس الأميركي.. لماذا لا يضعون التشريعات التي تضغط على الشركات التقنية لمراعاة الأخلاق في ما يتم برمجته؟ الجواب باختصار لأن معظم الشركات التقنية تحتفظ بخطط التطوير لديها بشكل سري جدا، وهناك فهم محدود جدا لدى المشرعين والمؤسسات القانونية لما يحصل، بسبب تعقيده، وبالتالي يصعب عليهم وضع الأطر القانونية لمعالجة ذلك. وباستثناء حالات بسيطة مثل ما حصل في أبريل الماضي عندما تمت معاقبة فيسبوك لما سمحت بتوجيه إعلاناتها لعرقية معينة، وهو ما يمثل مخالفة صريحة لروح القانون الأميركي، فإن هناك فجوة ضخمة بين التشريعات وبين الجوانب الأخلاقية ضمن أسوار الشركات التقنية العتيدة. وإذا كان الأمر في الولايات المتحدة وأوروبا فيه الكثير من الأمل بأن يتم معالجة هذا الموضوع بشكل أو بآخر خلال السنوات القادمة، فإن الأمر مختلف في دول أخرى أنظمتها ديكتاتورية ولا تهتم بحقوق الإنسان بشكل عام، وفي نفس الوقت تشهد تطورا سريعا ومذهلا في مجالات الذكاء الاصطناعي.تواجه شركات التقنية اليوم تحديا أساسيا مرتبطا بـ”أخلاقيات الذكاء الاصطناعي”وهذا يعني أنه في ظل غياب جهد عالمي يرعاه المجتمع الدولي فإن التحكم في هذا المجال سيكون من أكبر التحديات التي ستواجهها الإنسانية خلال العقود القادمة. بل أزيد على ذلك، أن الدول المستهلكة للتقنية ربما يكون لديها الحافز الأكبر لمعالجة هذه الموضوعات حتى لا تصبح مناطق للتجارب غير المقننة للشركات التي تجمع البيانات وتعالجها وتستخدمها لتعليم الآلة ما تفعله في المستقبل، ثم تصدر لنا الآلات التي نكتشف مشكلاتها في المستقبل يوما بعد يوم.بعض روايات الخيال العلمي كانت تصور الآلة على أنه الكائن المثالي الذي يعمل بلا أجندة ولا كراهية أو حقد، ليبني عالما أفضل، وهذا صحيح وجميل، ولكن الصورة الكاملة تقول إن الآلات تعمل كما تبرمجها، وإذا لم تأخذ أنظمة التعلم الذاتي القضايا الأخلاقية في الاعتبار فإن النتيجة ستكون مختلفة تماما.أعرف أن عنوان المقال متشائم، وهو في النهاية واحد من الاحتمالات لما يمكن أن يحصل خلال عقد من الزمن عندما تؤتي مشاريع تطوير الذكاء الاصطناعي وإنترنت الأشياء ثمارها، وتصبح واقعا في حياتنا، وهناك طبعا الاحتمال الآخر بأن ينمو اهتمام كاف بهذه الموضوعات وتكون الآلة المثال المشرق في التزامها بالقيم الأخلاقية. الإنسان هو الذي يطور الآلة، والإنسان هو الذي سيحدد مستقبلها.د. عمار بكارإعلامي وكاتب متخصص في شؤون الإعلام الرقمي والمستقبليات، والرئيس التنفيذي لشركة ييس تو ديجيتال ومركز ARC للأبحاث الاستراتيجية. عمل في عدة مناصب إعلامية واستشارية خلال أكثر من 20 سنة.