معاينة الصور في تويتر تفضل الوجوه البيضاء 

 تبحث منصة تويتر في سبب تفضيل الشبكة العصبونية – التي تستخدمها لتوليد معاينة الصور – إظهار وجوه الأشخاص البيض بشكل متكرر أكثر من الوجوه السوداء.وأظهر العديد من مستخدمي تويتر المشكلة خلال عطلة نهاية الأسبوع، حيث نشروا أمثلة على المشاركات التي تضمنت وجه شخص أسود ووجه شخص أبيض.وأظهرت معاينة تويتر الوجوه البيضاء في كثير من الأحيان، وبدأ الاختبار غير الرسمي بعد أن حاول أحد مستخدمي تويتر النشر عن مشكلة لاحظها في ميزة التعرف على الوجه في (Zoom)، حيث لم تكن تُظهر وجه زميل أسود في المكالمات. ولاحظ أن خوارزمية تويتر تفضل الوجه الأبيض على الوجه الأسود عندما نشر المشكلة على تويتر، واكتشف المستخدمون أن خوارزمية المعاينة اختارت شخصيات كرتونية غير سوداء أيضًا.وأوضح باحثو التعلم الآلي في تدوينة كيف بدأوا بالتعرف على الوجه لاقتصاص الصور، وذلك عندما بدأت المنصة لأول مرة في استخدام الشبكة العصبونية لاقتصاص معاينات الصور تلقائيًا.وقالت التدوينة: استخدمنا في السابق ميزة اكتشاف الوجه لتركيز الرؤية على أبرز وجه يمكننا العثور عليه، وبالرغم من أن هذا ليس استدلالًا غير منطقي، إلا أن النهج له حدود واضحة؛ نظرًا إلى أنه لا تحتوي جميع الصور على وجوه. وأضافت: “غالبًا ما يتجنب جهاز كشف الوجه لدينا الوجوه، وأحيانًا يكتشف الوجوه عن طريق الخطأ عندما لا يكون هناك أي وجوه، وفي حال لم يتم العثور على وجوه، فسنركز الرؤية على وسط الصورة، وقد يؤدي ذلك إلى اقتصاص صور المعاينة بشكل محرج”.وغرد كبير مسؤولي التصميم في تويتر، دانتلي ديفيس (Dantley Davis)، بأن الشركة كانت تحقق في الشبكة العصبونية، حيث أجرى بعض التجارب غير العلمية على الصور.وغردت ليز كيلي (Liz Kelley) من فريق التواصل في تويتر: بأن الشركة اختبرت التحيز قبل إرسال النموذج، لكنها لم تجد دليلًا على التحيز العنصري أو الجنسي في اختبارها. وكتبت كيلي عبر منصة تويتر: من الواضح من هذه الأمثلة أن لدينا المزيد من التحليل للقيام به، ونحن نبحث في هذا، ونواصل مشاركة ما نتعلمه والإجراءات التي نتخذها، وسنفتح مصدر عملنا حتى يتمكن الآخرون من المراجعة والتكرار.وغرد كبير مسؤولي التكنولوجيا في تويتر باراغ أغراوال (Parag Agrawal): أن النموذج بحاجة إلى تحسين مستمر، مضيفًا أنه حريص على التعلم من التجارب.